{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d5a7833",
   "metadata": {},
   "source": [
    "# COURSE: Big Data - CTS43135\n",
    "\n",
    "## Lab Instruction #5: Machine Learning with Spark MLlib\n",
    "\n",
    "### Lab Objectives:\n",
    "- Understand and practice data processing with PySpark and Spark MLlib.\n",
    "- Load and explore the dataset.\n",
    "- Perform feature preprocessing.\n",
    "- Define the model and build the pipeline.\n",
    "\n",
    "### Prerequisites:\n",
    "- Basic knowledge of Python, SQL, and Machine Learning is recommended.\n",
    "- This lab runs on Python 3.6+ with Apache Spark 3.x.\n",
    "- A working environment like Jupyter Notebook or Google Colab is recommended for easier execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c297e9",
   "metadata": {},
   "source": [
    "#### Activity 1: Load the dataset & Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14b7c5",
   "metadata": {},
   "source": [
    "#### 1. Download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddcc4136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('adult.csv', <http.client.HTTPMessage at 0x18fe8304250>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "urllib.request.urlretrieve(url, \"adult.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd1bcf2",
   "metadata": {},
   "source": [
    "#### 2. Display the First Few Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "123966e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39, State-gov, 77516, Bachelors, 13, Never-married, Adm-clerical, Not-in-family, White, Male, 2174, 0, 40, United-States, <=50K\n",
      "50, Self-emp-not-inc, 83311, Bachelors, 13, Married-civ-spouse, Exec-managerial, Husband, White, Male, 0, 0, 13, United-States, <=50K\n",
      "38, Private, 215646, HS-grad, 9, Divorced, Handlers-cleaners, Not-in-family, White, Male, 0, 0, 40, United-States, <=50K\n",
      "53, Private, 234721, 11th, 7, Married-civ-spouse, Handlers-cleaners, Husband, Black, Male, 0, 0, 40, United-States, <=50K\n",
      "28, Private, 338409, Bachelors, 13, Married-civ-spouse, Prof-specialty, Wife, Black, Female, 0, 0, 40, Cuba, <=50K\n"
     ]
    }
   ],
   "source": [
    "with open('adult.csv', 'r') as file:\n",
    "    for i in range(5):\n",
    "        print(file.readline().strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37eafbe",
   "metadata": {},
   "source": [
    "#### 3. Initialize a Spark Session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5419be80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"lab05\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a4f147",
   "metadata": {},
   "source": [
    "#### 4. Load the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebf15635",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"\"\"`age` DOUBLE,\n",
    "`workclass` STRING,\n",
    "`fnlwgt` DOUBLE,\n",
    "`education` STRING,\n",
    "`education_num` DOUBLE,\n",
    "`marital_status` STRING,\n",
    "`occupation` STRING,\n",
    "`relationship` STRING,\n",
    "`race` STRING,\n",
    "`sex` STRING,\n",
    "`capital_gain` DOUBLE,\n",
    "`capital_loss` DOUBLE,\n",
    "`hours_per_week` DOUBLE,\n",
    "`native_country` STRING,\n",
    "`income` STRING\"\"\"\n",
    "dataset = spark.read.csv(\"adult.csv\", schema=schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ff969",
   "metadata": {},
   "source": [
    "#### 5. Split the dataset into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19f91cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26076\n",
      "6485\n"
     ]
    }
   ],
   "source": [
    "trainDF, testDF = dataset.randomSplit([0.8, 0.2], seed=42)\n",
    "print(trainDF.cache().count()) # Cache because accessing training data multiple times\n",
    "print(testDF.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fbad92",
   "metadata": {},
   "source": [
    "#### 6. Data Exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0e3fa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|    hours_per_week|\n",
      "+-------+------------------+\n",
      "|  count|             26076|\n",
      "|   mean|  40.4284782942169|\n",
      "| stddev|12.404569739132008|\n",
      "|    min|               1.0|\n",
      "|    25%|              40.0|\n",
      "|    50%|              40.0|\n",
      "|    75%|              45.0|\n",
      "|    max|              99.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.select(\"hours_per_week\").summary().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db720c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|    education|count|\n",
      "+-------------+-----+\n",
      "|      HS-grad| 8408|\n",
      "| Some-college| 5860|\n",
      "|    Bachelors| 4255|\n",
      "|      Masters| 1388|\n",
      "|    Assoc-voc| 1102|\n",
      "|         11th|  958|\n",
      "|   Assoc-acdm|  845|\n",
      "|         10th|  748|\n",
      "|      7th-8th|  510|\n",
      "|  Prof-school|  465|\n",
      "|          9th|  419|\n",
      "|         12th|  361|\n",
      "|    Doctorate|  323|\n",
      "|      5th-6th|  265|\n",
      "|      1st-4th|  126|\n",
      "|    Preschool|   43|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.groupBy(\"education\").count().sort(\"count\", ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b22b40",
   "metadata": {},
   "source": [
    "### Activity 2: Feature preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64fbcc8",
   "metadata": {},
   "source": [
    "#### 1. Convert categorical variables to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b7d8d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "categoricalCols = [\"workclass\", \"education\", \"marital_status\", \"occupation\",\n",
    "\"relationship\", \"race\", \"sex\"]\n",
    "# The following two lines are estimators. They return functions that we will later apply to transform the dataset.\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=[x + \"Index\" for x in categoricalCols])\n",
    "encoder = OneHotEncoder(inputCols=stringIndexer.getOutputCols(), outputCols=[x + \"OHE\" for x in categoricalCols])\n",
    "# The label column (\"income\") is also a string value - it has two possible values, \"<=50K\" and \">50K\".\n",
    "# Convert it to a numeric value using StringIndexer.\n",
    "labelToIndex = StringIndexer(inputCol=\"income\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexerModel = stringIndexer.fit(trainDF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "590f0271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+--------+-------------+-------------+--------------+----------+---------------+-------------------+-------+------------+------------+--------------+--------------+------+\n",
      "| age|workclass|  fnlwgt|    education|education_num|marital_status|occupation|   relationship|               race|    sex|capital_gain|capital_loss|hours_per_week|native_country|income|\n",
      "+----+---------+--------+-------------+-------------+--------------+----------+---------------+-------------------+-------+------------+------------+--------------+--------------+------+\n",
      "|17.0|        ?| 34019.0|         10th|          6.0| Never-married|         ?|      Own-child|              White|   Male|         0.0|         0.0|          20.0| United-States| <=50K|\n",
      "|17.0|        ?| 34088.0|         12th|          8.0| Never-married|         ?|      Own-child|              White| Female|         0.0|         0.0|          25.0| United-States| <=50K|\n",
      "|17.0|        ?| 47407.0|         11th|          7.0| Never-married|         ?|      Own-child|              White|   Male|         0.0|         0.0|          10.0| United-States| <=50K|\n",
      "|17.0|        ?| 48703.0|         11th|          7.0| Never-married|         ?|      Own-child|              White| Female|         0.0|         0.0|          30.0| United-States| <=50K|\n",
      "|17.0|        ?| 48751.0|         11th|          7.0| Never-married|         ?|      Own-child|              Black| Female|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|17.0|        ?| 67808.0|         10th|          6.0| Never-married|         ?|      Own-child|              White|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|17.0|        ?| 86786.0|         10th|          6.0| Never-married|         ?|      Own-child|              White| Female|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|17.0|        ?| 89870.0|         10th|          6.0| Never-married|         ?|      Own-child|              White|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|17.0|        ?| 94366.0|         10th|          6.0| Never-married|         ?| Other-relative|              White|   Male|         0.0|         0.0|           6.0| United-States| <=50K|\n",
      "|17.0|        ?|103810.0|         12th|          8.0| Never-married|         ?|      Own-child|              White|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|17.0|        ?|110998.0| Some-college|         10.0| Never-married|         ?|      Own-child| Asian-Pac-Islander| Female|         0.0|         0.0|          40.0|   Philippines| <=50K|\n",
      "|17.0|        ?|112942.0|         10th|          6.0| Never-married|         ?|      Own-child|              White|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|17.0|        ?|114798.0|         11th|          7.0| Never-married|         ?|      Own-child|              White| Female|         0.0|         0.0|          18.0| United-States| <=50K|\n",
      "|17.0|        ?|127003.0|          9th|          5.0| Never-married|         ?|      Own-child|              Black|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|17.0|        ?|138507.0|         10th|          6.0| Never-married|         ?|      Own-child|              White|   Male|         0.0|         0.0|          20.0| United-States| <=50K|\n",
      "|17.0|        ?|144114.0|         10th|          6.0| Never-married|         ?|      Own-child|              White|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|17.0|        ?|145258.0|         11th|          7.0| Never-married|         ?| Other-relative|              White| Female|         0.0|         0.0|          25.0| United-States| <=50K|\n",
      "|17.0|        ?|145886.0|         11th|          7.0| Never-married|         ?|      Own-child|              White| Female|         0.0|         0.0|          30.0| United-States| <=50K|\n",
      "|17.0|        ?|151141.0|         10th|          6.0| Never-married|         ?|      Own-child|              White|   Male|         0.0|         0.0|          30.0| United-States| <=50K|\n",
      "|17.0|        ?|158762.0|         10th|          6.0| Never-married|         ?|      Own-child|              White| Female|         0.0|         0.0|          20.0| United-States| <=50K|\n",
      "+----+---------+--------+-------------+-------------+--------------+----------+---------------+-------------------+-------+------------+------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d264fcfc",
   "metadata": {},
   "source": [
    "#### 2. Combine all feature columns into a single feature vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "596e944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "# This includes both the numeric columns and the one-hot encoded binary vector columns in our dataset.\n",
    "numericCols = [\"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]\n",
    "assemblerInputs = [c + \"OHE\" for c in categoricalCols] + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3902f50c",
   "metadata": {},
   "source": [
    "### Activity 3: Define the model & Build the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53165ef7",
   "metadata": {},
   "source": [
    "#### 1. Create a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51c0cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LogisticRegression model from PySpark's MLlib\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "# Initialize a Logistic Regression model\n",
    "# - featuresCol: Specifies the column containing feature vectors\n",
    "# - labelCol: Specifies the column containing the target label (0 or 1)\n",
    "# - regParam: Regularization parameter (L2 regularization by default); helps prevent overfitting\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", regParam=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e1e0f0",
   "metadata": {},
   "source": [
    "#### 2. Build a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38afe204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "# Define the pipeline based on the stages created in previous steps.\n",
    "pipeline = Pipeline(stages=[stringIndexer, encoder, labelToIndex, vecAssembler,lr])\n",
    "# Define the pipeline model.\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "# Apply the pipeline model to the test dataset.\n",
    "predDF = pipelineModel.transform(testDF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b1a7fd",
   "metadata": {},
   "source": [
    "#### 3. Display the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b52707be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+\n",
      "|features                                                                                   |label|prediction|probability                             |\n",
      "+-------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+\n",
      "|(59,[3,13,24,36,45,48,53,54,55,58],[1.0,1.0,1.0,1.0,1.0,1.0,17.0,41643.0,7.0,15.0])        |0.0  |0.0       |[0.9062475766406436,0.09375242335935641]|\n",
      "|(59,[3,15,24,36,45,48,52,53,54,55,58],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,17.0,64785.0,6.0,30.0]) |0.0  |0.0       |[0.8927692098013015,0.10723079019869852]|\n",
      "|(59,[3,13,24,36,45,48,53,54,55,58],[1.0,1.0,1.0,1.0,1.0,1.0,17.0,80077.0,7.0,20.0])        |0.0  |0.0       |[0.9041098028218706,0.09589019717812941]|\n",
      "|(59,[3,13,24,36,45,48,52,53,54,55,58],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,17.0,104025.0,7.0,18.0])|0.0  |0.0       |[0.8952739426670617,0.10472605733293827]|\n",
      "|(59,[3,15,24,36,45,48,53,54,55,58],[1.0,1.0,1.0,1.0,1.0,1.0,17.0,139183.0,6.0,15.0])       |0.0  |0.0       |[0.908769684685861,0.09123031531413905] |\n",
      "+-------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select(\"features\", \"label\", \"prediction\", \"probability\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f8a464",
   "metadata": {},
   "source": [
    "#### 4. Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb9c5843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve: 0.8832451799218509\n",
      "Accuracy: 0.7680801850424056\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "bcEvaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "print(f\"Area under ROC curve: {bcEvaluator.evaluate(predDF)}\")\n",
    "\n",
    "mcEvaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(f\"Accuracy: {mcEvaluator.evaluate(predDF)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
