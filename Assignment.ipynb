{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3086649",
   "metadata": {},
   "source": [
    "# Lab Assignment: Sentiment Analysis on IMDB Movie Reviews \n",
    "\n",
    "## Objective \n",
    "- **Load and preprocess** an IMDB movie reviews dataset using PySpark MLlib.  \n",
    "- **Train a classifier** to predict the sentiment of movie reviews as positive or negative.  \n",
    "- **Evaluate model performance** using Accuracy, Precision, Recall, and F1-score.  \n",
    "\n",
    "---\n",
    "\n",
    "## Instructions \n",
    "\n",
    "### Download the IMDB Reviews Dataset:  \n",
    "This dataset contains 50,000 movie reviews labeled as positive or negative, which will be used to build a sentiment classification model.  \n",
    "\n",
    "### Your goal:  \n",
    "1. **Load and preprocess** the dataset, ensuring valid movie reviews and sentiment labels.  \n",
    "2. **Convert text labels** into binary format (0 = negative, 1 = positive).  \n",
    "3. **Clean the text data** by removing stopwords, punctuation, and lowercasing.  \n",
    "4. **Convert text reviews** into numerical features using TF-IDF or Word2Vec.  \n",
    "5. **Split the dataset** into training (80%) and testing (20%) sets.  \n",
    "6. **Train a classification model** in PySpark MLlib.  \n",
    "7. **Evaluate the model** using Accuracy, Precision, Recall, and F1-score.  \n",
    "\n",
    "---\n",
    "\n",
    "## Submission \n",
    "- **Submission deadline**: 2 weeks from the assignment date.  \n",
    "- **Submission Format**: Upload the Executed Notebook (or similar) to LMS ([lms.siu.edu.vn](https://lms.siu.edu.vn)).  \n",
    "\n",
    "---\n",
    "\n",
    "## Suggested Resources \n",
    "- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/index.html)  \n",
    "- [PySpark SQL Guide](https://spark.apache.org/sql/)  \n",
    "\n",
    "---\n",
    "\n",
    "## Student Information \n",
    "- **Name**: Thái Hồ Phú Gia  \n",
    "- **Class**: 23MMT  \n",
    "- **Student ID**: 11012302891  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dd687e",
   "metadata": {},
   "source": [
    "### Bước 0: Tải dataset (chỉ chạy khi chưa có tải dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# mkdir -p data && cd data\n",
    "\n",
    "# wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "\n",
    "# tar -xzf aclImdb_v1.tar.gz\n",
    "\n",
    "# rm aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d77259",
   "metadata": {},
   "source": [
    "### Bước 1: Khởi tạo Spark và import thư viện "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00aeb8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: findspark in /home/vscode/.local/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: pyspark in /home/vscode/.local/lib/python3.9/site-packages (3.5.5)\n",
      "Requirement already satisfied: numpy in /home/vscode/.local/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in /home/vscode/.local/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /home/vscode/.local/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: seaborn in /home/vscode/.local/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in /home/vscode/.local/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /home/vscode/.local/lib/python3.9/site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vscode/.local/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/vscode/.local/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/vscode/.local/lib/python3.9/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/vscode/.local/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/vscode/.local/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vscode/.local/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/vscode/.local/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vscode/.local/lib/python3.9/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vscode/.local/lib/python3.9/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/vscode/.local/lib/python3.9/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/vscode/.local/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/vscode/.local/lib/python3.9/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/vscode/.local/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/vscode/.local/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/07 08:14:21 WARN Utils: Your hostname, codespaces-41a89b resolves to a loopback address: 127.0.0.1; using 10.0.0.208 instead (on interface eth0)\n",
      "25/05/07 08:14:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/07 08:14:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "%pip install findspark pyspark numpy pandas matplotlib seaborn scikit-learn\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import input_file_name, lit, regexp_extract\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IMDB_Sentiment\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45729da3",
   "metadata": {},
   "source": [
    "### Bước 2: Load Dataset\n",
    "\n",
    "Chúng ta sẽ đọc thẳng file `.txt` trong:\n",
    "- `data/aclImdb/train/pos/` (label = 1)\n",
    "- `data/aclImdb/train/neg/` (label = 0)\n",
    "- tương tự cho `data/aclImdb/test/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec58418b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size = 25000, Test size = 25000\n",
      "+----------------------------------------------------------------------------------------------------+-----+\n",
      "|                                                                                              review|label|\n",
      "+----------------------------------------------------------------------------------------------------+-----+\n",
      "|Match 1: Tag Team Table Match Bubba Ray and Spike Dudley vs Eddie Guerrero and Chris Benoit Bubba...|    1|\n",
      "|**Attention Spoilers**<br /><br />First of all, let me say that Rob Roy is one of the best films ...|    1|\n",
      "|Titanic directed by James Cameron presents a fictional love story on the historical setting of th...|    1|\n",
      "|By now you've probably heard a bit about the new Disney dub of Miyazaki's classic film, Laputa: C...|    1|\n",
      "|*!!- SPOILERS - !!*<br /><br />Before I begin this, let me say that I have had both the advantage...|    1|\n",
      "+----------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_pos = spark.read.text(\"data/aclImdb/train/pos/*.txt\") \\\n",
    "    .withColumnRenamed(\"value\", \"review\") \\\n",
    "    .withColumn(\"label\", lit(1))\n",
    "\n",
    "\n",
    "train_neg = spark.read.text(\"data/aclImdb/train/neg/*.txt\") \\\n",
    "    .withColumnRenamed(\"value\", \"review\") \\\n",
    "    .withColumn(\"label\", lit(0))\n",
    "\n",
    "\n",
    "test_pos = spark.read.text(\"data/aclImdb/test/pos/*.txt\") \\\n",
    "    .withColumnRenamed(\"value\", \"review\") \\\n",
    "    .withColumn(\"label\", lit(1))\n",
    "\n",
    "test_neg = spark.read.text(\"data/aclImdb/test/neg/*.txt\") \\\n",
    "    .withColumnRenamed(\"value\", \"review\") \\\n",
    "    .withColumn(\"label\", lit(0))\n",
    "\n",
    "\n",
    "train_df = train_pos.union(train_neg)\n",
    "test_df  = test_pos.union(test_neg)\n",
    "full_df  = train_df.union(test_df)   \n",
    "\n",
    "\n",
    "print(f\"Train size = {train_df.count()}, Test size = {test_df.count()}\")\n",
    "train_df.show(5, truncate=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e8662",
   "metadata": {},
   "source": [
    "### Bước 3: Text Preprocessing\n",
    "\n",
    "- Tokenization\n",
    "- Lowercasing & loại bỏ punctuation (Spark Tokenizer đã lowercase tự động)\n",
    "- Stopwords removal\n",
    "- Chuyển sang vector numeric (TF–IDF hoặc Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "632b193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"review\", outputCol=\"words\")\n",
    "remover   = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "hashTF    = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf       = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "lr        = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=20)\n",
    "\n",
    "pipeline  = Pipeline(stages=[tokenizer, remover, hashTF, idf, lr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c14782",
   "metadata": {},
   "source": [
    "### Bước 4: Training & Evaluation\n",
    "\n",
    "- Fit Pipeline trên `train_df`  \n",
    "- Dự đoán trên `test_df`  \n",
    "- Tính Accuracy, Precision, Recall, F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66b2c031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/07 08:19:01 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|Metric           |Score |\n",
      "+-----------------+------+\n",
      "|accuracy         |0.7869|\n",
      "|weightedPrecision|0.7869|\n",
      "|weightedRecall   |0.7869|\n",
      "|f1               |0.7869|\n",
      "+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "model       = pipeline.fit(train_df)\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\")\n",
    "\n",
    "metrics = []\n",
    "for metric in [\"accuracy\", \"weightedPrecision\", \"weightedRecall\", \"f1\"]:\n",
    "    score = evaluator.setMetricName(metric).evaluate(predictions)\n",
    "    metrics.append(Row(Metric=metric, Score=score))\n",
    "\n",
    "\n",
    "metrics_df = spark.createDataFrame(metrics)\n",
    "metrics_df = metrics_df.withColumn(\"Score\", metrics_df[\"Score\"].cast(\"double\").alias(\"Score\").substr(0, 6))\n",
    "metrics_df.show(truncate=False)\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
